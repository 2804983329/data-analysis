{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "【课程3.2.2】  线性回归的python实现方法\n",
    "\n",
    "线性回归通常是人们在学习预测模型时首选的技术之一。在这种技术中，因变量是连续的，自变量可以是连续的也可以是离散的，回归线的性质是线性的。\n",
    "线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系\n",
    "\n",
    "简单线性回归 / 多元线性回归\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 简单线性回归（一元线性回归）\n",
    "# （1）数据示例\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# 导入线性回归模块\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "xtrain = 10 * rng.rand(30)\n",
    "ytrain = 8 + 4 * xtrain + rng.rand(30)\n",
    "# np.random.RandomState → 随机数种子，对于一个随机数发生器，只要该种子（seed）相同，产生的随机数序列就是相同的\n",
    "# 生成随机数据x与y\n",
    "# 样本关系：y = 8 + 4*x\n",
    "\n",
    "fig = plt.figure(figsize =(12,3))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plt.scatter(xtrain,ytrain,marker = '.',color = 'k')\n",
    "plt.grid()\n",
    "plt.title('样本数据散点图')\n",
    "# 生成散点图\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(xtrain[:,np.newaxis],ytrain)\n",
    "# LinearRegression → 线性回归评估器，用于拟合数据得到拟合直线\n",
    "# model.fit(x,y) → 拟合直线，参数分别为x与y\n",
    "# x[:,np.newaxis] → 将数组变成(n,1)形状 行转列\n",
    "#print(model.coef_)  #查看斜率\n",
    "#print(model.intercept) #截距\n",
    "\n",
    "xtest = np.linspace(0,10,1000)\n",
    "ytest = model.predict(xtest[:,np.newaxis])  #预测\n",
    "# 创建测试数据xtest，并根据拟合曲线求出ytest\n",
    "# model.predict → 预测\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plt.scatter(xtrain,ytrain,marker = '.',color = 'k')\n",
    "plt.plot(xtest,ytest,color = 'r')\n",
    "plt.grid()\n",
    "plt.title('线性回归拟合')\n",
    "# 绘制散点图、线性回归拟合直线\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 简单线性回归（一元线性回归）\n",
    "# （2）误差\n",
    "\n",
    "rng = np.random.RandomState(8)\n",
    "xtrain = 10 * rng.rand(15)\n",
    "ytrain = 8 + 4 * xtrain + rng.rand(15) * 30\n",
    "model.fit(xtrain[:,np.newaxis],ytrain)\n",
    "xtest = np.linspace(0,10,1000)\n",
    "ytest = model.predict(xtest[:,np.newaxis])\n",
    "# 创建样本数据并进行拟合\n",
    "\n",
    "plt.plot(xtest,ytest,color = 'r',linestyle = '--')  # 拟合直线\n",
    "plt.scatter(xtrain,ytrain,marker = '.',color = 'k')  # 样本数据散点图\n",
    "ytest2 = model.predict(xtrain[:,np.newaxis])  # 样本数据x在拟合直线上的y值\n",
    "plt.scatter(xtrain,ytest2,marker = 'x',color = 'g')   # ytest2散点图\n",
    "plt.plot([xtrain,xtrain],[ytrain,ytest2],color = 'gray')  # 误差线\n",
    "plt.grid()\n",
    "plt.title('误差')\n",
    "# 绘制图表\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 简单线性回归（一元线性回归）\n",
    "# （3）求解a，b\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "xtrain = 10 * rng.rand(30)\n",
    "ytrain = 8 + 4 * xtrain + rng.rand(30)\n",
    "# 创建数据\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(xtrain[:,np.newaxis],ytrain)\n",
    "# 回归拟合\n",
    "\n",
    "print('斜率a为：%.4f' % model.coef_[0])\n",
    "print('截距b为：%.4f' % model.intercept_)\n",
    "print('线性回归函数为：\\ny = %.4fx + %.4f' % (model.coef_[0],model.intercept_))\n",
    "# 参数输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 多元线性回归\n",
    "\n",
    "rng = np.random.RandomState(5)\n",
    "xtrain = 10 * rng.rand(150,4)\n",
    "ytrain = 20 + np.dot(xtrain ,[1.5,2,-4,3])\n",
    "df = pd.DataFrame(xtrain, columns = ['b1','b2','b3','b4'])\n",
    "df['y'] = ytrain\n",
    "pd.scatter_matrix(df[['b1','b2','b3','b4']],figsize=(10,6),\n",
    "                 diagonal='kde',\n",
    "                 alpha = 0.5,\n",
    "                 range_padding=0.1)\n",
    "print(df.head())\n",
    "# 创建数据，其中包括4个自变量\n",
    "# 4个变量相互独立\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(df[['b1','b2','b3','b4']],df['y'])\n",
    "# 多元回归拟合\n",
    "\n",
    "print('斜率a为：' ,model.coef_)\n",
    "print('截距b为：%.4f' % model.intercept_)\n",
    "print('线性回归函数为：\\ny = %.1fx1 + %.1fx2 + %.1fx3 + %.1fx4 + %.1f'\n",
    "      % (model.coef_[0],model.coef_[1],model.coef_[2],model.coef_[3],model.intercept_))\n",
    "# 参数输出\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "【课程3.2.3】  线性回归模型评估\n",
    "\n",
    "通过几个参数验证回归模型\n",
    "\n",
    "SSE(和方差、误差平方和)：The sum of squares due to error\n",
    "MSE(均方差、方差)：Mean squared error\n",
    "RMSE(均方根、标准差)：Root mean squared error\n",
    "R-square(确定系数) Coefficient of determination\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 模型评价\n",
    "# MSE, RMES, R-square\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "xtrain = 10 * rng.rand(30)\n",
    "ytrain = 8 + 4 * xtrain + rng.rand(30) * 3\n",
    "# 创建数据\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(xtrain[:,np.newaxis],ytrain)\n",
    "# 多元回归拟合\n",
    "\n",
    "ytest = model.predict(xtrain[:,np.newaxis])  # 求出预测数据\n",
    "mse = metrics.mean_squared_error(ytrain,ytest)  # 求出均方差\n",
    "rmse = np.sqrt(mse)  # 求出均方根\n",
    "\n",
    "#ssr = ((ytest - ytrain.mean())**2).sum()  # 求出预测数据与原始数据均值之差的平方和\n",
    "#sst = ((ytrain - ytrain.mean())**2).sum()  # 求出原始数据和均值之差的平方和\n",
    "#r2 = ssr / sst # 求出确定系数\n",
    "\n",
    "r2 = model.score(xtrain[:,np.newaxis],ytrain)  # 求出确定系数\n",
    "print(\"均方差MSE为: %.5f\" % mse)\n",
    "print(\"均方根RMSE为: %.5f\" % rmse)\n",
    "print(\"确定系数R-square为: %.5f\" % r2)\n",
    "# 确定系数R-square非常接近于1，线性回归模型拟合较好"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}