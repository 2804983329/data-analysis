{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "【课程3.4.2】  PCA主成分分析的python实现方法\n",
    "\n",
    "最广泛无监督算法 + 基础的降维算法\n",
    "通过线性变换将原始数据变换为一组各维度线性无关的表示，用于提取数据的主要特征分量 → 高维数据的降维\n",
    "\n",
    "二维数据降维 / 多维数据降维\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 二维数据降维\n",
    "# 数据创建\n",
    "rng = np.random.RandomState(8)\n",
    "data = np.dot(rng.rand(2,2),rng.randn(2,200)).T\n",
    "df = pd.DataFrame({'X1':data[:,0],\n",
    "                    'X2':data[:,1]})\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "plt.scatter(df['X1'],df['X2'], alpha = 0.8, marker = '.')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "# 生成图表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 二维数据降维\n",
    "# 构建模型，分析主成分\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# 加载主成分分析模块PCA\n",
    "\n",
    "pca = PCA(n_components = 1)  # n_components = 1 → 降为1维\n",
    "pca.fit(df)  # 构建模型\n",
    "# sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False)\n",
    "# n_components:  PCA算法中所要保留的主成分个数n，也即保留下来的特征个数n\n",
    "# copy: True或者False，默认为True → 表示是否在运行算法时，将原始训练数据复制一份\n",
    "# fit(X,y=None) → 调用fit方法的对象本身。比如pca.fit(X)，表示用X对pca这个对象进行训练\n",
    "\n",
    "print(pca.explained_variance_)  # 输出特征值\n",
    "print(pca.components_)  # 输出特征向量\n",
    "print(pca.n_components_)  # 输出成分的个数\n",
    "print('-----')\n",
    "# components_：返回具有最大方差的成分。\n",
    "# explained_variance_ratio_：返回 所保留的n个成分各自的方差百分比。\n",
    "# n_components_：返回所保留的成分个数n。\n",
    "\n",
    "# 这里是shape(200,2)降为shape(200,1)，只有1个特征值，对应2个特征向量\n",
    "# 降维后主成分 A1 = 0.7788006 * X1 + 0.62727158 * X2\n",
    "\n",
    "x_pca = pca.transform(df)  # 数据转换\n",
    "x_new = pca.inverse_transform(x_pca)  # 将降维后的数据转换成原始数据\n",
    "print('original shape:',df.shape)\n",
    "print('transformed shape:',x_pca.shape)\n",
    "print(x_pca[:5])\n",
    "print('-----')\n",
    "# 主成分分析，生成新的向量x_pca\n",
    "# fit_transform(X) → 用X来训练PCA模型，同时返回降维后的数据，这里x_pca就是降维后的数据\n",
    "# inverse_transform() → 将降维后的数据转换成原始数据\n",
    "\n",
    "plt.scatter(df['X1'],df['X2'], alpha = 0.8, marker = '.')\n",
    "plt.scatter(x_new[:,0],x_new[:,1], alpha = 0.8, marker = '.',color = 'r')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "# 生成图表"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}